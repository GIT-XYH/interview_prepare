1> 数仓建模工具
    PowerDesigner/SQLYog
    做离线的时候数仓中总共有五百多张表

数据采集汇聚层:
    ① app 事件日志的采集
    ② 业务库的数据抽取
    分别用了 flume 和 sqoop 来实现
数据计算层: 主要用 hive 作为基础设施搭建一个数仓, 分层分主题进行各类报表计算
任务调度主要使用 azkaban
元数据管理引入了 atlas, 基本的元数据管理需求都能满足
2> 数仓分层
    ODS 层(贴源层或数据操作层):(app端埋点日志, pc 端埋点日志, 内容格式为 json, 文件格式为 text, 压缩编码为 orc)
        （1）保持数据原貌不做任何修改，起到备份数据的作用。
        （2）数据采用压缩，减少磁盘存储空间（例如：原始数据100G，可以压缩到10G左右）
        （3）创建分区表，防止后续的全表扫描
    DWD 层(数据明细层):(数据清洗, 使用 sql, json 数据打平)
        这一层的表定义和表数量和 ODS 相差不大
        生成全量快照和拉链表, 生成 guid
            GUID唯一表示生成（IDMAPPING）
            理解guid生成的意义：
            核心要点，为匿名访问设备绑定一个标识
            贯通一个用户在一个设备上注册前后的行为。
            贯通一个注册用户在不同设备上登录之后的行为
            理解“直接使用设备id做为统一标识”，“一对一绑定”，“多对一绑定”方案的利弊
            理解我们所采用的方案：“动态绑定”的含义
            彻底梳理，GUID标识生成的代码逻辑流程：
            1.从当天日志中，抽取每台设备上，每个账号的第一条记录，并分别为这些账号按先后打分；
            2.加载上一日的“绑定评分”历史结果，并与当日的“绑定评分”进行合并（评分累加，或者评分衰减）；
            3.根据合并后的“绑定评分”，根据“分数高低，时间先后”进行guid的选定；
        DWD层需构建维度模型，一般采用星型模型，呈现的状态一般为星座模型。
        维度建模一般按照以下四个步骤：
        选择业务过程→声明粒度→确认维度→确认事实
    DWS 层(数仓服务层):(主要做一些轻度聚合)
        比如在事件维度上, 做一些日粒度, 周粒度, 月粒度, 季力度等相关指标
        DWS层统计各个主题对象的当天行为，服务于DWT层的主题宽表。如图所示，DWS层的宽表字段，是站在不同维度的视角去看事实表，
        重点关注事实表的度量值，通过与之关联的事实表，获得不同的事实表的度量值。
    DWT层:
        以分析的主题对象为建模驱动，基于上层的应用和产品的指标需求，构建主题对象的全量宽表(60-80 字段)。
    ADS层(数仓应用层):(主要是各种最终报表的计算和存储层)
        分别对设备主题、会员主题、商品主题和营销主题进行指标分析，其中营销主题是用户主题和商品主题的跨主题分析案例

        数仓CUBE操作术语备忘

        SLICE (切片)
        将某一个（或多个）维度上的值锁定，只观察当这个维度取这个值时的情形，相当于将一个立方体做了一个切片。

        DICE (切块）
        将某一个（或多个）维度上的值固定在一个区间内，观察这个取值区间内cube的情形，相当于将一个立方体做了一个切块。

        ROLL UP (上卷)
        沿着某一个（或多个）维度进行聚合，观察聚合后其他维度上的汇总数据，相当于将一个立方体沿着某个维度压缩（聚合）在一起。

        DRILL DOWN (下钻）
        沿着某一个（或多个）维度在更细粒度层面上进行展开，观察展开后其他维度上的对应数据，相当于将一个立方体沿着某个维度拉伸，拉伸的结果就是粒度变细，比如时间维度从季度拉伸到月。

        下钻和上卷是两个相反的操作，取名上并不能很好地顾名思义，简单的解释两个操作就是：在某一个（或多个）维度上是进行更细粒度放大观察还是最粗粒度的聚合观察，就像是图片编辑工具中的zoom in和zoom out!

        PIVOT (旋转）
        将维度的位置互换。在二维表格中就是行变列，列变行。

3> 星型模型和雪花模型
    星型模型和雪花模型是在维度表和事实表的关系上衍生出来的一种逻辑上的建表的模型，当多个维度表全部指向同一个事实表的时候，
    这个模型就是星型模型；如果多个维度表中有一部分表指向事实表，其他维度表指向一个中心维度表（也就是把其中一个维度表进一
    步分层，这个模型就是雪花模型。星型模型很明显会存储很多冗余数据，是一个不规范表，雪花模型在星型模型基础上，进一步分解维度，
    减少了冗余。然而由于建立了多层的连接，有时候在查询的时候效率可能并没有星型模型更快，而且后期维护也不是很方便，
    所以更多的情况还是使用的是星型模型。

Bit-map的基本思想就是用一个bit位来标记某个元素对应的Value，而Key即是该元素。由于采用了Bit为单位来存储数据，因此在存储空间方面，可以大大节省。（PS：划重点 节省存储空间）
假设有这样一个需求：在20亿个随机整数中找出某个数m是否存在其中，并假设32位操作系统，4G内存
在Java中，int占4字节，1字节=8位（1 byte = 8 bit）
如果每个数字用int存储，那就是20亿个int，因而占用的空间约为  (2000000000*4/1024/1024/1024)≈7.45G
如果按位存储就不一样了，20亿个数就是20亿位，占用空间约为  (2000000000/8/1024/1024/1024)≈0.233G
高下立判，无需多言
主要用于大量元素的快速查找, 排序, 去重

olap 引擎--Kylin(麒麟)
它主要是通过预计算的方式将用户设定的多维立方体缓存到HBase中, 是 Hadoop 之上的 SQL 查询接口, 是一种高性能的 SQL on hadoop 工具, 能够在
亚秒内查询 Hive 表

1.7.2 Sqoop导入导出Null存储一致性问题
Hive中的Null在底层是以“\N”来存储，而MySQL中的Null在底层就是Null，为了保证数据两端的一致性。
在导出数据时采用--input-null-string和--input-null-non-string两个参数。
导入数据时采用--null-string和--null-non-string。

1.7.5 Sqoop一天导入多少数据
100万日活=》10万订单，1人10条，每天1g左右业务数据
Sqoop每天将1G的数据量导入到数仓。

1.7.6 Sqoop数据导出的时候一次执行多长时间
每天晚上00:10开始执行，Sqoop任务一般情况20-30分钟的都有。取决于数据量（11.11，6.18等活动在1个小时左右）。

1.7.7 Sqoop在导入数据的时候数据倾斜
Sqoop参数撇嘴： split-by：按照自增主键来切分表的工作单元。
num-mappers：启动N个map来并行导入数据，默认4个；

1.8.1 每天集群运行多少指标?
每天跑100多个指标，有活动时跑200个左右。

1.8.2 任务挂了怎么办？
1）运行成功或者失败都会发邮件、发钉钉、集成自动打电话（项目中遇到的问题）
2）最主要的解决方案就是重新跑。
3）报警网站http://www.onealert.com/

拉链表:
    拉链表是针对数据仓库设计中表存储数据的方式而定义的，顾名思义，所谓拉链，就是记录历史。记录一个事物从开始，一直到当前状态的所有变化的信息。

    我们先看一个示例，这就是一张拉链表，存储的是用户的最基本信息以及每条记录的生命周期。我们可以使用这张表拿到最新的当天的最新数据以及之前的历史数据。

    注册日期	用户编号	手机号码	t_start_date	t_end_date
    2017-01-01	001	111111	2017-01-01	9999-12-31
    2017-01-01	002	222222	2017-01-01	2017-01-01
    2017-01-01	002	233333	2017-01-02	9999-12-31
    2017-01-01	003	333333	2017-01-01	9999-12-31
    2017-01-01	004	444444	2017-01-01	2017-01-01
    2017-01-01	004	432432	2017-01-02	2017-01-02
    2017-01-01	004	432432	2017-01-03	9999-12-31
    2017-01-02	005	555555	2017-01-02	2017-01-02
    2017-01-02	005	115115	2017-01-03	9999-12-31
    2017-01-03	006	666666	2017-01-03	9999-12-31
    我们暂且不对这张表做细致的讲解，后文会专门来阐述怎么来设计、实现和使用它。

    拉链表的使用场景
    在数据仓库的数据模型设计过程中，经常会遇到下面这种表的设计：

    有一些表的数据量很大，比如一张用户表，大约10亿条记录，50个字段，这种表，即使使用ORC压缩，单张表的存储也会超过100G，在HDFS使用双备份或者三备份的话就更大一些。
    表中的部分字段会被update更新操作，如用户联系方式，产品的描述信息，订单的状态等等。
    需要查看某一个时间点或者时间段的历史快照信息，比如，查看某一个订单在历史某一个时间点的状态。
    表中的记录变化的比例和频率不是很大，比如，总共有10亿的用户，每天新增和发生变化的有200万左右，变化的比例占的很小。

azkaban 是一个批量工作流任务调度器, 用于在一个工作流内以一个特定的顺序运行一组工作和流程, azkaban 定义了一种 KV 文件格式
来简历任务之间的依赖关系, 并提供了一个易于使用的 web 用户界面维护和跟踪工作流