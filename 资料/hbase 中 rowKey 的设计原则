rowKey 的设计原则
    1> 长度原则:
        rowKey是一个二进制码流，可以是任意字符串，最大长度 64kb ，实际应用中一般为10-100bytes，以byte[], 形式保存，
        一般设计成定长。建议越短越好，不要超过16个字节，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。
    2> 唯一原则:
        rowKey是按照字典顺序排序存储的，因此，设计rowkey的时候，要充分利用这个排序的特点，将经常读取的数据存储到一块。
    3>散列原则:
        如果 Rowkey 是按时间戳的方式递增，不要将时间放在二进制码的前面，建议将 Rowkey 的高位作为散列字段，由程序循环生成，低位放时间字段，
        这样将提高数据均衡分布在每个 Regionserver 实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息将产生所有 新数据都在一个
        RegionServer 上堆积的热点现象，这样在做数据检索的时候负载将会集中 在个别 RegionServer，降低查询效率。row key是按照字典序存储，
        因此，设计row key时，要充分利用这个排序特点，将经常一起读取的数据存储到一块，将最近可能会被访问的数据放在一块。
        举个例子：如果最近写入HBase表中的数据是最可能被访问的，可以考虑将时间戳作为row key的一部分，由于是字典序排序，
        所以可以使用Long.MAX_VALUE - timestamp作为row key，这样能保证新写入的数据在读取时可以被快速命中。

    哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来
    访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表

    rowKey 如何设计: 生成随机数, hash, 散列

    1. 能用 spark 写离线框架吗
    	可以
    	flume 日志采集到 hdfs; 数据清洗, 通过 spark, hive 等, 清洗完再放回 hdfs, RDD 算子处理数据; 处理结果入库, 放到 nosql 数据库中,
    	ck, hbase;可视化